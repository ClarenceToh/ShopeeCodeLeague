{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Marketing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGth9mrxob1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtpB2Gs9o-Sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFzA0ScypDp6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "fec7a930-140e-48bc-f5a4-0edf45e2f2c8"
      },
      "source": [
        "!cp kaggle.json ~/.kaggle/\n",
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                         title                                             size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------  -----------------------------------------------  -----  -------------------  -------------  \n",
            "andrewmvd/data-analyst-jobs                                 Data Analyst Jobs                                  2MB  2020-07-14 08:37:57           1959  \n",
            "vzrenggamani/hanacaraka                                     Aksara Jawa / Hanacaraka                           9MB  2020-07-10 15:09:31             71  \n",
            "mrgeislinger/bart-ridership                                 BART Ridership                                   325MB  2020-07-09 22:28:07            198  \n",
            "moezabid/zillow-all-homes-data                              Zillow All Homes Data                              5MB  2020-07-18 11:44:48            824  \n",
            "mrmorj/restaurant-recommendation-challenge                  Restaurant Recommendation Challenge              534MB  2020-07-18 16:25:04            814  \n",
            "vishnuvarthanrao/windows-store                              Windows Store                                     93KB  2020-07-07 12:29:07           1111  \n",
            "tanmoyx/covid19-patient-precondition-dataset                COVID-19 patient pre-condition dataset             8MB  2020-07-22 16:37:50           1419  \n",
            "rohanrao/chai-time-data-science                             Chai Time Data Science | CTDS.Show                 3MB  2020-07-23 17:23:46            727  \n",
            "garystafford/environmental-sensor-data-132k                 Environmental Sensor Telemetry Data                7MB  2020-07-20 17:18:10            292  \n",
            "mdabbert/ultimate-ufc-dataset                               Ultimate UFC Dataset                             533KB  2020-08-03 19:53:36            595  \n",
            "benroshan/factors-affecting-campus-placement                Campus Recruitment                                 5KB  2020-04-11 11:09:02          12864  \n",
            "bobbyscience/league-of-legends-diamond-ranked-games-10-min  League of Legends Diamond Ranked Games (10 min)  539KB  2020-04-13 13:53:02           5158  \n",
            "fireballbyedimyrnmom/us-counties-covid-19-dataset           US counties COVID 19 dataset                       4MB  2020-08-03 12:29:06          10986  \n",
            "divyansh22/flight-delay-prediction                          January Flight Delay Prediction                   23MB  2020-04-14 13:15:41           4319  \n",
            "clmentbisaillon/fake-and-real-news-dataset                  Fake and real news dataset                        41MB  2020-03-26 18:51:15          11017  \n",
            "ikiulian/global-hospital-beds-capacity-for-covid19          Global Hospital Beds Capacity (for covid-19)     284KB  2020-04-26 09:39:35           3758  \n",
            "praveengovi/coronahack-chest-xraydataset                    CoronaHack -Chest X-Ray-Dataset                    1GB  2020-03-20 01:26:40           5199  \n",
            "bappekim/air-pollution-in-seoul                             Air Pollution in Seoul                            20MB  2020-04-03 16:33:49           5256  \n",
            "kimjihoo/coronavirusdataset                                 Data Science for COVID-19 (DS4C)                   7MB  2020-07-13 14:07:31          49698  \n",
            "sudalairajkumar/novel-corona-virus-2019-dataset             Novel Corona Virus 2019 Dataset                    2MB  2020-08-02 13:07:45         233941  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTkiEw6LpIZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "d69bd565-a6ef-41fe-d09e-c8807f6ef1d8"
      },
      "source": [
        "!kaggle competitions download -c open-shopee-code-league-marketing-analytics\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content\n",
            "  0% 0.00/1.23M [00:00<?, ?B/s]\n",
            "100% 1.23M/1.23M [00:00<00:00, 85.7MB/s]\n",
            "Downloading sample_submission_0_1.csv to /content\n",
            "  0% 0.00/481k [00:00<?, ?B/s]\n",
            "100% 481k/481k [00:00<00:00, 64.0MB/s]\n",
            "Downloading users.csv.zip to /content\n",
            "  0% 0.00/519k [00:00<?, ?B/s]\n",
            "100% 519k/519k [00:00<00:00, 70.0MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            "  0% 0.00/940k [00:00<?, ?B/s]\n",
            "100% 940k/940k [00:00<00:00, 61.3MB/s]\n",
            "kaggle.json  sample_submission_0_1.csv\ttrain.csv.zip\n",
            "sample_data  test.csv.zip\t\tusers.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x50jvdMpaBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQg6CsDypeoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv.zip')\n",
        "test = pd.read_csv('test.csv.zip')\n",
        "sample_sub = pd.read_csv('sample_submission_0_1.csv')\n",
        "users = pd.read_csv('users.csv.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G3f2Nelprjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "f4843236-dadf-42c0-e096-fdecbd3271e8"
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country_code</th>\n",
              "      <th>user_id</th>\n",
              "      <th>subject_line_length</th>\n",
              "      <th>open_count_last_10_days</th>\n",
              "      <th>open_count_last_30_days</th>\n",
              "      <th>open_count_last_60_days</th>\n",
              "      <th>login_count_last_10_days</th>\n",
              "      <th>login_count_last_30_days</th>\n",
              "      <th>login_count_last_60_days</th>\n",
              "      <th>checkout_count_last_10_days</th>\n",
              "      <th>checkout_count_last_30_days</th>\n",
              "      <th>checkout_count_last_60_days</th>\n",
              "      <th>open_flag</th>\n",
              "      <th>row_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>73539.000000</td>\n",
              "      <td>73539.000000</td>\n",
              "      <td>73539.000000</td>\n",
              "      <td>73539.000000</td>\n",
              "      <td>73539.000000</td>\n",
              "      <td>73539.000000</td>\n",
              "      <td>73539.000000</td>\n",
              "      <td>73539.000000</td>\n",
              "      <td>73539.000000</td>\n",
              "      <td>73539.000000</td>\n",
              "      <td>73539.000000</td>\n",
              "      <td>73539.000000</td>\n",
              "      <td>73539.000000</td>\n",
              "      <td>73539.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.533159</td>\n",
              "      <td>63048.595358</td>\n",
              "      <td>43.656373</td>\n",
              "      <td>0.911829</td>\n",
              "      <td>2.780457</td>\n",
              "      <td>5.019364</td>\n",
              "      <td>8.382287</td>\n",
              "      <td>25.284053</td>\n",
              "      <td>49.010430</td>\n",
              "      <td>0.909898</td>\n",
              "      <td>2.796040</td>\n",
              "      <td>5.420960</td>\n",
              "      <td>0.155781</td>\n",
              "      <td>36769.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.675251</td>\n",
              "      <td>36068.006037</td>\n",
              "      <td>11.219323</td>\n",
              "      <td>1.754052</td>\n",
              "      <td>4.570239</td>\n",
              "      <td>7.902313</td>\n",
              "      <td>13.424436</td>\n",
              "      <td>37.853189</td>\n",
              "      <td>71.819327</td>\n",
              "      <td>2.887416</td>\n",
              "      <td>7.686064</td>\n",
              "      <td>13.980182</td>\n",
              "      <td>0.362650</td>\n",
              "      <td>21229.02506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>31679.500000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18384.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>63340.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>36769.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>94731.500000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>55153.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>127925.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>735.000000</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>531.000000</td>\n",
              "      <td>783.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>73538.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       country_code        user_id  ...     open_flag       row_id\n",
              "count  73539.000000   73539.000000  ...  73539.000000  73539.00000\n",
              "mean       2.533159   63048.595358  ...      0.155781  36769.00000\n",
              "std        1.675251   36068.006037  ...      0.362650  21229.02506\n",
              "min        1.000000       2.000000  ...      0.000000      0.00000\n",
              "25%        1.000000   31679.500000  ...      0.000000  18384.50000\n",
              "50%        2.000000   63340.000000  ...      0.000000  36769.00000\n",
              "75%        3.000000   94731.500000  ...      0.000000  55153.50000\n",
              "max        7.000000  127925.000000  ...      1.000000  73538.00000\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpPySrqwp9XD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "d1e03c41-6542-4046-ed9e-4fffc0fc91f9"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 73539 entries, 0 to 73538\n",
            "Data columns (total 18 columns):\n",
            " #   Column                       Non-Null Count  Dtype \n",
            "---  ------                       --------------  ----- \n",
            " 0   country_code                 73539 non-null  int64 \n",
            " 1   grass_date                   73539 non-null  object\n",
            " 2   user_id                      73539 non-null  int64 \n",
            " 3   subject_line_length          73539 non-null  int64 \n",
            " 4   last_open_day                73539 non-null  object\n",
            " 5   last_login_day               73539 non-null  object\n",
            " 6   last_checkout_day            73539 non-null  object\n",
            " 7   open_count_last_10_days      73539 non-null  int64 \n",
            " 8   open_count_last_30_days      73539 non-null  int64 \n",
            " 9   open_count_last_60_days      73539 non-null  int64 \n",
            " 10  login_count_last_10_days     73539 non-null  int64 \n",
            " 11  login_count_last_30_days     73539 non-null  int64 \n",
            " 12  login_count_last_60_days     73539 non-null  int64 \n",
            " 13  checkout_count_last_10_days  73539 non-null  int64 \n",
            " 14  checkout_count_last_30_days  73539 non-null  int64 \n",
            " 15  checkout_count_last_60_days  73539 non-null  int64 \n",
            " 16  open_flag                    73539 non-null  int64 \n",
            " 17  row_id                       73539 non-null  int64 \n",
            "dtypes: int64(14), object(4)\n",
            "memory usage: 10.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WImHXTFZp_2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "03075ce6-fb53-42f8-d09f-82553aea3351"
      },
      "source": [
        "train.head()\n",
        "# users.head()\n",
        "# test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country_code</th>\n",
              "      <th>grass_date</th>\n",
              "      <th>user_id</th>\n",
              "      <th>subject_line_length</th>\n",
              "      <th>last_open_day</th>\n",
              "      <th>last_login_day</th>\n",
              "      <th>last_checkout_day</th>\n",
              "      <th>open_count_last_10_days</th>\n",
              "      <th>open_count_last_30_days</th>\n",
              "      <th>open_count_last_60_days</th>\n",
              "      <th>login_count_last_10_days</th>\n",
              "      <th>login_count_last_30_days</th>\n",
              "      <th>login_count_last_60_days</th>\n",
              "      <th>checkout_count_last_10_days</th>\n",
              "      <th>checkout_count_last_30_days</th>\n",
              "      <th>checkout_count_last_60_days</th>\n",
              "      <th>open_flag</th>\n",
              "      <th>row_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>2019-07-16 00:00:00+08:00</td>\n",
              "      <td>43</td>\n",
              "      <td>44</td>\n",
              "      <td>19</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>43</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>2019-07-16 00:00:00+08:00</td>\n",
              "      <td>102</td>\n",
              "      <td>44</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>48</td>\n",
              "      <td>90</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>2019-07-16 00:00:00+08:00</td>\n",
              "      <td>177</td>\n",
              "      <td>49</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>69</td>\n",
              "      <td>119</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2019-07-16 00:00:00+08:00</td>\n",
              "      <td>184</td>\n",
              "      <td>49</td>\n",
              "      <td>49</td>\n",
              "      <td>9</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>69</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>2019-07-16 00:00:00+08:00</td>\n",
              "      <td>221</td>\n",
              "      <td>49</td>\n",
              "      <td>227</td>\n",
              "      <td>6</td>\n",
              "      <td>221</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   country_code                 grass_date  ...  open_flag  row_id\n",
              "0             4  2019-07-16 00:00:00+08:00  ...          0       0\n",
              "1             4  2019-07-16 00:00:00+08:00  ...          1       1\n",
              "2             6  2019-07-16 00:00:00+08:00  ...          0       2\n",
              "3             1  2019-07-16 00:00:00+08:00  ...          0       3\n",
              "4             6  2019-07-16 00:00:00+08:00  ...          0       4\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0zSEDO2rhdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "720ab575-daa5-4bc3-9efb-cefe663e0611"
      },
      "source": [
        "train.open_flag.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzY3rIkHr9_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "3aa4b196-9f15-4d86-cc30-ce4281557d22"
      },
      "source": [
        "print(train.corr()[\"open_flag\"].abs().sort_values(ascending=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "open_flag                      1.000000\n",
            "open_count_last_10_days        0.515307\n",
            "open_count_last_30_days        0.507853\n",
            "open_count_last_60_days        0.477766\n",
            "country_code                   0.158945\n",
            "subject_line_length            0.057357\n",
            "row_id                         0.037443\n",
            "checkout_count_last_10_days    0.015573\n",
            "login_count_last_10_days       0.014023\n",
            "checkout_count_last_30_days    0.013419\n",
            "checkout_count_last_60_days    0.010231\n",
            "login_count_last_30_days       0.010134\n",
            "login_count_last_60_days       0.008633\n",
            "user_id                        0.008082\n",
            "Name: open_flag, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dZDSdAssZ9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_after = train.drop(['user_id', 'grass_date', 'row_id'], axis=1)\n",
        "test_after = test.drop(['user_id', 'grass_date', 'row_id'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tj7MrHZxkH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def only_num(df):\n",
        "    df1 = df.apply(pd.to_numeric, args=('coerce',))\n",
        "    df1 = df1.fillna(0)\n",
        "    return df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_2VC-8008aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_after = only_num(train_after)\n",
        "test_after = only_num(test_after)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2n5LcSNtJ5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "8ea49cb9-c196-4c68-9667-470c4cc5b699"
      },
      "source": [
        "print(train_after.corr()[\"open_flag\"].abs().sort_values(ascending=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "open_flag                      1.000000\n",
            "open_count_last_10_days        0.515307\n",
            "open_count_last_30_days        0.507853\n",
            "open_count_last_60_days        0.477766\n",
            "country_code                   0.158945\n",
            "last_open_day                  0.151467\n",
            "subject_line_length            0.057357\n",
            "checkout_count_last_10_days    0.015573\n",
            "login_count_last_10_days       0.014023\n",
            "checkout_count_last_30_days    0.013419\n",
            "checkout_count_last_60_days    0.010231\n",
            "login_count_last_30_days       0.010134\n",
            "login_count_last_60_days       0.008633\n",
            "last_login_day                 0.001884\n",
            "last_checkout_day              0.000497\n",
            "Name: open_flag, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6wErY7x1Thn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6fa30e4-9644-4800-fb51-96c730e93231"
      },
      "source": [
        "y = train_after.open_flag\n",
        "y = list(y)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94HDywnZ1qGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "47ca19b3-8a31-4218-f9b2-596431c4041f"
      },
      "source": [
        "train_after"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country_code</th>\n",
              "      <th>subject_line_length</th>\n",
              "      <th>last_open_day</th>\n",
              "      <th>last_login_day</th>\n",
              "      <th>last_checkout_day</th>\n",
              "      <th>open_count_last_10_days</th>\n",
              "      <th>open_count_last_30_days</th>\n",
              "      <th>open_count_last_60_days</th>\n",
              "      <th>login_count_last_10_days</th>\n",
              "      <th>login_count_last_30_days</th>\n",
              "      <th>login_count_last_60_days</th>\n",
              "      <th>checkout_count_last_10_days</th>\n",
              "      <th>checkout_count_last_30_days</th>\n",
              "      <th>checkout_count_last_60_days</th>\n",
              "      <th>open_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>44</td>\n",
              "      <td>19.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>43</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>44</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>48</td>\n",
              "      <td>90</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>49</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>69</td>\n",
              "      <td>119</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>49.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>69</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>49</td>\n",
              "      <td>227.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73534</th>\n",
              "      <td>6</td>\n",
              "      <td>39</td>\n",
              "      <td>24.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>279.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73535</th>\n",
              "      <td>2</td>\n",
              "      <td>38</td>\n",
              "      <td>46.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73536</th>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73537</th>\n",
              "      <td>2</td>\n",
              "      <td>38</td>\n",
              "      <td>5.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73538</th>\n",
              "      <td>6</td>\n",
              "      <td>39</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>73539 rows  15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       country_code  ...  open_flag\n",
              "0                 4  ...          0\n",
              "1                 4  ...          1\n",
              "2                 6  ...          0\n",
              "3                 1  ...          0\n",
              "4                 6  ...          0\n",
              "...             ...  ...        ...\n",
              "73534             6  ...          0\n",
              "73535             2  ...          0\n",
              "73536             2  ...          0\n",
              "73537             2  ...          1\n",
              "73538             6  ...          0\n",
              "\n",
              "[73539 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh-VzrYItike",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "73bfb82d-280c-489d-d4a3-6490b16689d3"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "x = train_after.drop(['open_flag'], axis=1).values #returns a numpy array\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x)\n",
        "col_names = list(train_after.drop(['open_flag'], axis=1).columns)\n",
        "train_scaled = pd.DataFrame(x_scaled, columns=col_names)\n",
        "train_scaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country_code</th>\n",
              "      <th>subject_line_length</th>\n",
              "      <th>last_open_day</th>\n",
              "      <th>last_login_day</th>\n",
              "      <th>last_checkout_day</th>\n",
              "      <th>open_count_last_10_days</th>\n",
              "      <th>open_count_last_30_days</th>\n",
              "      <th>open_count_last_60_days</th>\n",
              "      <th>login_count_last_10_days</th>\n",
              "      <th>login_count_last_30_days</th>\n",
              "      <th>login_count_last_60_days</th>\n",
              "      <th>checkout_count_last_10_days</th>\n",
              "      <th>checkout_count_last_30_days</th>\n",
              "      <th>checkout_count_last_60_days</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.523077</td>\n",
              "      <td>0.023515</td>\n",
              "      <td>0.000331</td>\n",
              "      <td>0.012457</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021739</td>\n",
              "      <td>0.029630</td>\n",
              "      <td>0.047244</td>\n",
              "      <td>0.058503</td>\n",
              "      <td>0.078571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009416</td>\n",
              "      <td>0.012771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.523077</td>\n",
              "      <td>0.011139</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>0.005536</td>\n",
              "      <td>0.064516</td>\n",
              "      <td>0.097826</td>\n",
              "      <td>0.125926</td>\n",
              "      <td>0.070866</td>\n",
              "      <td>0.065306</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.006369</td>\n",
              "      <td>0.001883</td>\n",
              "      <td>0.005109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.017327</td>\n",
              "      <td>0.000276</td>\n",
              "      <td>0.003460</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>0.094488</td>\n",
              "      <td>0.093878</td>\n",
              "      <td>0.094444</td>\n",
              "      <td>0.031847</td>\n",
              "      <td>0.035782</td>\n",
              "      <td>0.034483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.060644</td>\n",
              "      <td>0.000496</td>\n",
              "      <td>0.036678</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007407</td>\n",
              "      <td>0.035433</td>\n",
              "      <td>0.031293</td>\n",
              "      <td>0.054762</td>\n",
              "      <td>0.006369</td>\n",
              "      <td>0.005650</td>\n",
              "      <td>0.007663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.280941</td>\n",
              "      <td>0.000331</td>\n",
              "      <td>0.152941</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007874</td>\n",
              "      <td>0.006803</td>\n",
              "      <td>0.003968</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73534</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.446154</td>\n",
              "      <td>0.029703</td>\n",
              "      <td>0.001984</td>\n",
              "      <td>0.193080</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>0.007407</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73535</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.430769</td>\n",
              "      <td>0.056931</td>\n",
              "      <td>0.000551</td>\n",
              "      <td>0.035294</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007407</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73536</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.338462</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73537</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.430769</td>\n",
              "      <td>0.006188</td>\n",
              "      <td>0.001874</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064516</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.029630</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73538</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.446154</td>\n",
              "      <td>0.001238</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064516</td>\n",
              "      <td>0.021739</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>73539 rows  14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       country_code  ...  checkout_count_last_60_days\n",
              "0          0.500000  ...                     0.012771\n",
              "1          0.500000  ...                     0.005109\n",
              "2          0.833333  ...                     0.034483\n",
              "3          0.000000  ...                     0.007663\n",
              "4          0.833333  ...                     0.000000\n",
              "...             ...  ...                          ...\n",
              "73534      0.833333  ...                     0.000000\n",
              "73535      0.166667  ...                     0.000000\n",
              "73536      0.166667  ...                     0.000000\n",
              "73537      0.166667  ...                     0.000000\n",
              "73538      0.833333  ...                     0.000000\n",
              "\n",
              "[73539 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyJUvdAe3eyx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "70052e4c-b316-4083-ae5f-a41aafe94fe2"
      },
      "source": [
        "xx = test_after.values #returns a numpy array\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "xx_scaled = min_max_scaler.fit_transform(xx)\n",
        "col_namess = list(test_after.columns)\n",
        "test_scaled = pd.DataFrame(xx_scaled, columns=col_namess)\n",
        "test_scaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country_code</th>\n",
              "      <th>subject_line_length</th>\n",
              "      <th>last_open_day</th>\n",
              "      <th>last_login_day</th>\n",
              "      <th>last_checkout_day</th>\n",
              "      <th>open_count_last_10_days</th>\n",
              "      <th>open_count_last_30_days</th>\n",
              "      <th>open_count_last_60_days</th>\n",
              "      <th>login_count_last_10_days</th>\n",
              "      <th>login_count_last_30_days</th>\n",
              "      <th>login_count_last_60_days</th>\n",
              "      <th>checkout_count_last_10_days</th>\n",
              "      <th>checkout_count_last_30_days</th>\n",
              "      <th>checkout_count_last_60_days</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.033251</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.008892</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.037975</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.030395</td>\n",
              "      <td>0.045576</td>\n",
              "      <td>0.103077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014851</td>\n",
              "      <td>0.029557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.008621</td>\n",
              "      <td>0.000275</td>\n",
              "      <td>0.261970</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.012658</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.015198</td>\n",
              "      <td>0.006702</td>\n",
              "      <td>0.003846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.205882</td>\n",
              "      <td>0.041872</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.002052</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.039514</td>\n",
              "      <td>0.025469</td>\n",
              "      <td>0.029231</td>\n",
              "      <td>0.007937</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>0.003284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.367647</td>\n",
              "      <td>0.077586</td>\n",
              "      <td>0.000275</td>\n",
              "      <td>0.003420</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130699</td>\n",
              "      <td>0.147453</td>\n",
              "      <td>0.133077</td>\n",
              "      <td>0.007937</td>\n",
              "      <td>0.012376</td>\n",
              "      <td>0.008210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.007389</td>\n",
              "      <td>0.000275</td>\n",
              "      <td>0.036936</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012158</td>\n",
              "      <td>0.016086</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55965</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.617647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>0.005472</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55966</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.617647</td>\n",
              "      <td>0.072660</td>\n",
              "      <td>0.044151</td>\n",
              "      <td>0.825581</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55967</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000385</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55968</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.006158</td>\n",
              "      <td>0.000275</td>\n",
              "      <td>0.004104</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.063291</td>\n",
              "      <td>0.116667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55969</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.617647</td>\n",
              "      <td>0.006158</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.013680</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.177215</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>55970 rows  14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       country_code  ...  checkout_count_last_60_days\n",
              "0          0.833333  ...                     0.029557\n",
              "1          0.833333  ...                     0.000000\n",
              "2          0.666667  ...                     0.003284\n",
              "3          0.000000  ...                     0.008210\n",
              "4          0.666667  ...                     0.003284\n",
              "...             ...  ...                          ...\n",
              "55965      0.833333  ...                     0.000000\n",
              "55966      0.833333  ...                     0.000000\n",
              "55967      0.833333  ...                     0.000000\n",
              "55968      0.833333  ...                     0.000000\n",
              "55969      0.833333  ...                     0.000000\n",
              "\n",
              "[55970 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RpCcBmu2VwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_scaled['open_flag']= y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EZApkuj2SkV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "e2c1d33f-8bfd-471b-d8c4-803964675591"
      },
      "source": [
        "print(train_scaled.corr()[\"open_flag\"].abs().sort_values(ascending=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "open_flag                      1.000000\n",
            "open_count_last_10_days        0.515307\n",
            "open_count_last_30_days        0.507853\n",
            "open_count_last_60_days        0.477766\n",
            "country_code                   0.158945\n",
            "last_open_day                  0.151467\n",
            "subject_line_length            0.057357\n",
            "checkout_count_last_10_days    0.015573\n",
            "login_count_last_10_days       0.014023\n",
            "checkout_count_last_30_days    0.013419\n",
            "checkout_count_last_60_days    0.010231\n",
            "login_count_last_30_days       0.010134\n",
            "login_count_last_60_days       0.008633\n",
            "last_login_day                 0.001884\n",
            "last_checkout_day              0.000497\n",
            "Name: open_flag, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTy5xsDAXGRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_scaled = train_scaled.drop(['subject_line_length','checkout_count_last_10_days','login_count_last_10_days','checkout_count_last_30_days','checkout_count_last_60_days','login_count_last_30_days','login_count_last_60_days','last_login_day','last_checkout_day'],axis=1)\n",
        "test_scaled = test_scaled.drop(['subject_line_length','checkout_count_last_10_days','login_count_last_10_days','checkout_count_last_30_days','checkout_count_last_60_days','login_count_last_30_days','login_count_last_60_days','last_login_day','last_checkout_day'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmzC4KfwTGDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zer = train_scaled[train_scaled.open_flag==0]\n",
        "one = train_scaled[train_scaled.open_flag==1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAKsJOirTY-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8d18f72d-d556-441d-a287-1869d502eaba"
      },
      "source": [
        "print(len(zer))\n",
        "print(len(one))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62083\n",
            "11456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZBwuIywSlq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "# upsample minority\n",
        "one_upsampled = resample(one,\n",
        "                          replace=True, # sample with replacement\n",
        "                          n_samples=len(zer), # match number in majority class\n",
        "                          random_state=27) # reproducible results\n",
        "zer_downsampled = resample(zer,\n",
        "                          replace=True, # sample with replacement\n",
        "                          n_samples=len(one), # match number in majority class\n",
        "                          random_state=27) # reproducible results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcrCx3P8Tsa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_scaled = pd.concat([zer,one_upsampled])\n",
        "# train_scaled = pd.concat([zer_downsampled,one])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqP1m8S83z-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "predictors = train_scaled.drop(\"open_flag\",axis=1)\n",
        "target = train_scaled[\"open_flag\"]\n",
        "\n",
        "X_train,Y_train = predictors,target\n",
        "\n",
        "#,Y_train,Y_test = train_test_split(predictors,target,test_size=0.20,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW04JN8d3-sN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36SfJsqY4Ar_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "81091464-4133-47a2-d151-5bfab78b3ca3"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train,Y_train)\n",
        "Y_pred_lr = lr.predict(X_test)\n",
        "score_lr = round(accuracy_score(Y_pred_lr,Y_test)*100,2)\n",
        "print(\"The accuracy score achieved using Logistic Regression is: \"+str(score_lr)+\" %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy score achieved using Logistic Regression is: 88.29 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxEKn_IH4JUF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "96cf0956-0e7e-4815-9ddb-81b51b4932c2"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train,Y_train)\n",
        "Y_pred_nb = nb.predict(X_test)\n",
        "score_nb = round(accuracy_score(Y_pred_nb,Y_test)*100,2)\n",
        "print(\"The accuracy score achieved using Naive Bayes is: \"+str(score_nb)+\" %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy score achieved using Naive Bayes is: 86.68 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mEDeJI64WOT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "48f9e3ea-fa23-46a4-e7c2-97532b1393e2"
      },
      "source": [
        "from sklearn import svm\n",
        "sv = svm.SVC(kernel='linear')\n",
        "sv.fit(X_train, Y_train)\n",
        "Y_pred_svm = sv.predict(X_test)\n",
        "score_svm = round(accuracy_score(Y_pred_svm,Y_test)*100,2)\n",
        "print(\"The accuracy score achieved using Linear SVM is: \"+str(score_svm)+\" %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy score achieved using Linear SVM is: 87.98 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M686duJe4eyf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24c34c5b-3ea7-4f77-e4e1-ea8977a71504"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "max_accuracy = 0\n",
        "\n",
        "\n",
        "for x in range(200):\n",
        "    dt = DecisionTreeClassifier(random_state=x)\n",
        "    dt.fit(X_train,Y_train)\n",
        "    Y_pred_dt = dt.predict(X_test)\n",
        "    current_accuracy = round(accuracy_score(Y_pred_dt,Y_test)*100,2)\n",
        "    if(current_accuracy>max_accuracy):\n",
        "        max_accuracy = current_accuracy\n",
        "        best_x = x\n",
        "        \n",
        "#print(max_accuracy)\n",
        "#print(best_x)\n",
        "\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=best_x)\n",
        "dt.fit(X_train,Y_train)\n",
        "Y_pred_dt = dt.predict(X_test)\n",
        "score_dt = round(accuracy_score(Y_pred_dt,Y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using Decision Tree is: \"+str(score_dt)+\" %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy score achieved using Decision Tree is: 83.17 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRtgR-bK4i_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "max_accuracy = 0\n",
        "\n",
        "\n",
        "for x in range(2000):\n",
        "    rf = RandomForestClassifier(random_state=x)\n",
        "    rf.fit(X_train,Y_train)\n",
        "    Y_pred_rf = rf.predict(X_test)\n",
        "    current_accuracy = round(accuracy_score(Y_pred_rf,Y_test)*100,2)\n",
        "    if(current_accuracy>max_accuracy):\n",
        "        max_accuracy = current_accuracy\n",
        "        best_x = x\n",
        "        \n",
        "#print(max_accuracy)\n",
        "#print(best_x)\n",
        "\n",
        "rf = RandomForestClassifier(random_state=best_x)\n",
        "rf.fit(X_train,Y_train)\n",
        "Y_pred_rf = rf.predict(X_test)\n",
        "score_rf = round(accuracy_score(Y_pred_rf,Y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using Decision Tree is: \"+str(score_rf)+\" %\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpLsfBtv4l2P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "3467e392-2ac7-4c9a-afb6-bdedd38c275e"
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
        "xgb_model.fit(X_train, Y_train)\n",
        "\n",
        "# Y_pred_xgb = xgb_model.predict(test_scaled)\n",
        "# score_xgb = round(accuracy_score(Y_pred_xgb,Y_test)*100,2)\n",
        "\n",
        "# print(\"The accuracy score achieved using XGBoost is: \"+str(score_xgb)+\" %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=42,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YQIo6a84sLx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "334045fc-f0a6-4d58-b915-57bf2a374a54"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model = Sequential()\n",
        "model.add(Dense(11,activation='relu',input_dim=14))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,epochs=300)\n",
        "Y_pred_nn = model.predict(X_test)\n",
        "Y_pred_nn = [round(x[0]) for x in Y_pred_nn]\n",
        "score_nn = round(accuracy_score(Y_pred_nn,Y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using Neural Network is: \"+str(score_nn)+\" %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "58831/58831 [==============================] - 5s 89us/step - loss: 0.3561 - accuracy: 0.8658\n",
            "Epoch 2/300\n",
            "58831/58831 [==============================] - 3s 46us/step - loss: 0.3108 - accuracy: 0.8789\n",
            "Epoch 3/300\n",
            "58831/58831 [==============================] - 4s 65us/step - loss: 0.3087 - accuracy: 0.8800\n",
            "Epoch 4/300\n",
            "58831/58831 [==============================] - 3s 47us/step - loss: 0.3075 - accuracy: 0.8804\n",
            "Epoch 5/300\n",
            "58831/58831 [==============================] - 2s 39us/step - loss: 0.3068 - accuracy: 0.8804\n",
            "Epoch 6/300\n",
            "58831/58831 [==============================] - 2s 38us/step - loss: 0.3064 - accuracy: 0.8801\n",
            "Epoch 7/300\n",
            "58831/58831 [==============================] - 2s 37us/step - loss: 0.3060 - accuracy: 0.8806\n",
            "Epoch 8/300\n",
            "58831/58831 [==============================] - 2s 40us/step - loss: 0.3059 - accuracy: 0.8798\n",
            "Epoch 9/300\n",
            "58831/58831 [==============================] - 2s 38us/step - loss: 0.3057 - accuracy: 0.8803\n",
            "Epoch 10/300\n",
            "58831/58831 [==============================] - 2s 37us/step - loss: 0.3057 - accuracy: 0.8801\n",
            "Epoch 11/300\n",
            "58831/58831 [==============================] - 2s 37us/step - loss: 0.3056 - accuracy: 0.8802\n",
            "Epoch 12/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3055 - accuracy: 0.8800\n",
            "Epoch 13/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3055 - accuracy: 0.8804\n",
            "Epoch 14/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3055 - accuracy: 0.8802\n",
            "Epoch 15/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3054 - accuracy: 0.8803\n",
            "Epoch 16/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3054 - accuracy: 0.8803\n",
            "Epoch 17/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3054 - accuracy: 0.8796\n",
            "Epoch 18/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3053 - accuracy: 0.8798\n",
            "Epoch 19/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3053 - accuracy: 0.8802\n",
            "Epoch 20/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3053 - accuracy: 0.8801\n",
            "Epoch 21/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3052 - accuracy: 0.8800\n",
            "Epoch 22/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3052 - accuracy: 0.8801\n",
            "Epoch 23/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3052 - accuracy: 0.8801\n",
            "Epoch 24/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3052 - accuracy: 0.8804\n",
            "Epoch 25/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3052 - accuracy: 0.8803\n",
            "Epoch 26/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3052 - accuracy: 0.8803\n",
            "Epoch 27/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3051 - accuracy: 0.8802\n",
            "Epoch 28/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3052 - accuracy: 0.8803\n",
            "Epoch 29/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3051 - accuracy: 0.8805\n",
            "Epoch 30/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3051 - accuracy: 0.8800\n",
            "Epoch 31/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3051 - accuracy: 0.8806\n",
            "Epoch 32/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3051 - accuracy: 0.8805\n",
            "Epoch 33/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3050 - accuracy: 0.8803\n",
            "Epoch 34/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3050 - accuracy: 0.8803\n",
            "Epoch 35/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3050 - accuracy: 0.8801\n",
            "Epoch 36/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3050 - accuracy: 0.8802\n",
            "Epoch 37/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3050 - accuracy: 0.8803\n",
            "Epoch 38/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3051 - accuracy: 0.8805\n",
            "Epoch 39/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3051 - accuracy: 0.8805\n",
            "Epoch 40/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3049 - accuracy: 0.8804\n",
            "Epoch 41/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3049 - accuracy: 0.8807\n",
            "Epoch 42/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3050 - accuracy: 0.8808\n",
            "Epoch 43/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3050 - accuracy: 0.8804\n",
            "Epoch 44/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3049 - accuracy: 0.8804\n",
            "Epoch 45/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3048 - accuracy: 0.8808\n",
            "Epoch 46/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3048 - accuracy: 0.8805\n",
            "Epoch 47/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3047 - accuracy: 0.8801\n",
            "Epoch 48/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3047 - accuracy: 0.8807\n",
            "Epoch 49/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3048 - accuracy: 0.8801\n",
            "Epoch 50/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3048 - accuracy: 0.8802\n",
            "Epoch 51/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3048 - accuracy: 0.8805\n",
            "Epoch 52/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3047 - accuracy: 0.8808\n",
            "Epoch 53/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3047 - accuracy: 0.8806\n",
            "Epoch 54/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3046 - accuracy: 0.8804\n",
            "Epoch 55/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3047 - accuracy: 0.8807\n",
            "Epoch 56/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3048 - accuracy: 0.8804\n",
            "Epoch 57/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3046 - accuracy: 0.8808\n",
            "Epoch 58/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3047 - accuracy: 0.8806\n",
            "Epoch 59/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3046 - accuracy: 0.8806\n",
            "Epoch 60/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3046 - accuracy: 0.8805\n",
            "Epoch 61/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3045 - accuracy: 0.8803\n",
            "Epoch 62/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3046 - accuracy: 0.8808\n",
            "Epoch 63/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3047 - accuracy: 0.8809\n",
            "Epoch 64/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3045 - accuracy: 0.8801\n",
            "Epoch 65/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3046 - accuracy: 0.8806\n",
            "Epoch 66/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3047 - accuracy: 0.8813\n",
            "Epoch 67/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3045 - accuracy: 0.8804\n",
            "Epoch 68/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3045 - accuracy: 0.8806\n",
            "Epoch 69/300\n",
            "58831/58831 [==============================] - 2s 40us/step - loss: 0.3046 - accuracy: 0.8809\n",
            "Epoch 70/300\n",
            "58831/58831 [==============================] - 2s 39us/step - loss: 0.3046 - accuracy: 0.8807\n",
            "Epoch 71/300\n",
            "58831/58831 [==============================] - 2s 39us/step - loss: 0.3045 - accuracy: 0.8805\n",
            "Epoch 72/300\n",
            "58831/58831 [==============================] - 2s 38us/step - loss: 0.3045 - accuracy: 0.8805\n",
            "Epoch 73/300\n",
            "58831/58831 [==============================] - 2s 36us/step - loss: 0.3044 - accuracy: 0.8807\n",
            "Epoch 74/300\n",
            "58831/58831 [==============================] - 2s 38us/step - loss: 0.3045 - accuracy: 0.8806\n",
            "Epoch 75/300\n",
            "58831/58831 [==============================] - 2s 38us/step - loss: 0.3045 - accuracy: 0.8803\n",
            "Epoch 76/300\n",
            "58831/58831 [==============================] - 2s 39us/step - loss: 0.3046 - accuracy: 0.8802\n",
            "Epoch 77/300\n",
            "58831/58831 [==============================] - 2s 38us/step - loss: 0.3045 - accuracy: 0.8808\n",
            "Epoch 78/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3045 - accuracy: 0.8810\n",
            "Epoch 79/300\n",
            "58831/58831 [==============================] - 2s 36us/step - loss: 0.3044 - accuracy: 0.8807\n",
            "Epoch 80/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3044 - accuracy: 0.8807\n",
            "Epoch 81/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3045 - accuracy: 0.8813\n",
            "Epoch 82/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3044 - accuracy: 0.8806\n",
            "Epoch 83/300\n",
            "58831/58831 [==============================] - 2s 36us/step - loss: 0.3044 - accuracy: 0.8806\n",
            "Epoch 84/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3044 - accuracy: 0.8809\n",
            "Epoch 85/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3044 - accuracy: 0.8803\n",
            "Epoch 86/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3044 - accuracy: 0.8809\n",
            "Epoch 87/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3044 - accuracy: 0.8809\n",
            "Epoch 88/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3044 - accuracy: 0.8811\n",
            "Epoch 89/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3044 - accuracy: 0.8807\n",
            "Epoch 90/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3043 - accuracy: 0.8804\n",
            "Epoch 91/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3044 - accuracy: 0.8807\n",
            "Epoch 92/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3042 - accuracy: 0.8806\n",
            "Epoch 93/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3044 - accuracy: 0.8804\n",
            "Epoch 94/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3043 - accuracy: 0.8803\n",
            "Epoch 95/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3043 - accuracy: 0.8805\n",
            "Epoch 96/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3044 - accuracy: 0.8808\n",
            "Epoch 97/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3043 - accuracy: 0.8809\n",
            "Epoch 98/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3043 - accuracy: 0.8810\n",
            "Epoch 99/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3044 - accuracy: 0.8805\n",
            "Epoch 100/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3043 - accuracy: 0.8804\n",
            "Epoch 101/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3042 - accuracy: 0.8806\n",
            "Epoch 102/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3044 - accuracy: 0.8806\n",
            "Epoch 103/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3043 - accuracy: 0.8801\n",
            "Epoch 104/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3043 - accuracy: 0.8807\n",
            "Epoch 105/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3041 - accuracy: 0.8810\n",
            "Epoch 106/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3042 - accuracy: 0.8805\n",
            "Epoch 107/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3042 - accuracy: 0.8803\n",
            "Epoch 108/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3042 - accuracy: 0.8808\n",
            "Epoch 109/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3041 - accuracy: 0.8804\n",
            "Epoch 110/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3040 - accuracy: 0.8809\n",
            "Epoch 111/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3042 - accuracy: 0.8806\n",
            "Epoch 112/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3041 - accuracy: 0.8806\n",
            "Epoch 113/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3042 - accuracy: 0.8807\n",
            "Epoch 114/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3041 - accuracy: 0.8812\n",
            "Epoch 115/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3041 - accuracy: 0.8807\n",
            "Epoch 116/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3041 - accuracy: 0.8809\n",
            "Epoch 117/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3040 - accuracy: 0.8809\n",
            "Epoch 118/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3040 - accuracy: 0.8805\n",
            "Epoch 119/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3041 - accuracy: 0.8807\n",
            "Epoch 120/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3040 - accuracy: 0.8807\n",
            "Epoch 121/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3040 - accuracy: 0.8808\n",
            "Epoch 122/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3039 - accuracy: 0.8806\n",
            "Epoch 123/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3040 - accuracy: 0.8808\n",
            "Epoch 124/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3040 - accuracy: 0.8809\n",
            "Epoch 125/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3040 - accuracy: 0.8805\n",
            "Epoch 126/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3040 - accuracy: 0.8805\n",
            "Epoch 127/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3039 - accuracy: 0.8807\n",
            "Epoch 128/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3038 - accuracy: 0.8810\n",
            "Epoch 129/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3039 - accuracy: 0.8810\n",
            "Epoch 130/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3039 - accuracy: 0.8807\n",
            "Epoch 131/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3040 - accuracy: 0.8806\n",
            "Epoch 132/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3038 - accuracy: 0.8810\n",
            "Epoch 133/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3038 - accuracy: 0.8808\n",
            "Epoch 134/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3038 - accuracy: 0.8812\n",
            "Epoch 135/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3039 - accuracy: 0.8807\n",
            "Epoch 136/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3038 - accuracy: 0.8805\n",
            "Epoch 137/300\n",
            "58831/58831 [==============================] - 2s 36us/step - loss: 0.3038 - accuracy: 0.8805\n",
            "Epoch 138/300\n",
            "58831/58831 [==============================] - 2s 37us/step - loss: 0.3039 - accuracy: 0.8808\n",
            "Epoch 139/300\n",
            "58831/58831 [==============================] - 2s 37us/step - loss: 0.3036 - accuracy: 0.8810\n",
            "Epoch 140/300\n",
            "58831/58831 [==============================] - 2s 37us/step - loss: 0.3038 - accuracy: 0.8811\n",
            "Epoch 141/300\n",
            "58831/58831 [==============================] - 2s 37us/step - loss: 0.3037 - accuracy: 0.8811\n",
            "Epoch 142/300\n",
            "58831/58831 [==============================] - 2s 37us/step - loss: 0.3037 - accuracy: 0.8810\n",
            "Epoch 143/300\n",
            "58831/58831 [==============================] - 2s 37us/step - loss: 0.3037 - accuracy: 0.8809\n",
            "Epoch 144/300\n",
            "58831/58831 [==============================] - 2s 36us/step - loss: 0.3037 - accuracy: 0.8808\n",
            "Epoch 145/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3037 - accuracy: 0.8806\n",
            "Epoch 146/300\n",
            "58831/58831 [==============================] - 2s 36us/step - loss: 0.3037 - accuracy: 0.8806\n",
            "Epoch 147/300\n",
            "58831/58831 [==============================] - 2s 36us/step - loss: 0.3037 - accuracy: 0.8811\n",
            "Epoch 148/300\n",
            "58831/58831 [==============================] - 2s 37us/step - loss: 0.3036 - accuracy: 0.8811\n",
            "Epoch 149/300\n",
            "58831/58831 [==============================] - 2s 42us/step - loss: 0.3036 - accuracy: 0.8806\n",
            "Epoch 150/300\n",
            "58831/58831 [==============================] - 3s 44us/step - loss: 0.3035 - accuracy: 0.8805\n",
            "Epoch 151/300\n",
            "58831/58831 [==============================] - 2s 39us/step - loss: 0.3036 - accuracy: 0.8807\n",
            "Epoch 152/300\n",
            "58831/58831 [==============================] - 2s 36us/step - loss: 0.3036 - accuracy: 0.8811\n",
            "Epoch 153/300\n",
            "58831/58831 [==============================] - 2s 37us/step - loss: 0.3036 - accuracy: 0.8809\n",
            "Epoch 154/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3036 - accuracy: 0.8812\n",
            "Epoch 155/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3035 - accuracy: 0.8809\n",
            "Epoch 156/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3036 - accuracy: 0.8805\n",
            "Epoch 157/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3036 - accuracy: 0.8804\n",
            "Epoch 158/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3034 - accuracy: 0.8811\n",
            "Epoch 159/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3034 - accuracy: 0.8806\n",
            "Epoch 160/300\n",
            "58831/58831 [==============================] - 2s 38us/step - loss: 0.3033 - accuracy: 0.8812\n",
            "Epoch 161/300\n",
            "58831/58831 [==============================] - 2s 37us/step - loss: 0.3033 - accuracy: 0.8814\n",
            "Epoch 162/300\n",
            "58831/58831 [==============================] - 2s 36us/step - loss: 0.3032 - accuracy: 0.8810\n",
            "Epoch 163/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3031 - accuracy: 0.8811\n",
            "Epoch 164/300\n",
            "58831/58831 [==============================] - 2s 36us/step - loss: 0.3031 - accuracy: 0.8810\n",
            "Epoch 165/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3030 - accuracy: 0.8813\n",
            "Epoch 166/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3029 - accuracy: 0.8809\n",
            "Epoch 167/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3029 - accuracy: 0.8812\n",
            "Epoch 168/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3028 - accuracy: 0.8810\n",
            "Epoch 169/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3027 - accuracy: 0.8811\n",
            "Epoch 170/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3026 - accuracy: 0.8814\n",
            "Epoch 171/300\n",
            "58831/58831 [==============================] - 2s 36us/step - loss: 0.3026 - accuracy: 0.8814\n",
            "Epoch 172/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3023 - accuracy: 0.8814\n",
            "Epoch 173/300\n",
            "58831/58831 [==============================] - 2s 37us/step - loss: 0.3024 - accuracy: 0.8813\n",
            "Epoch 174/300\n",
            "58831/58831 [==============================] - 2s 36us/step - loss: 0.3023 - accuracy: 0.8813\n",
            "Epoch 175/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3022 - accuracy: 0.8811\n",
            "Epoch 176/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3020 - accuracy: 0.8813\n",
            "Epoch 177/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3021 - accuracy: 0.8813\n",
            "Epoch 178/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3022 - accuracy: 0.8813\n",
            "Epoch 179/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3021 - accuracy: 0.8813\n",
            "Epoch 180/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3021 - accuracy: 0.8814\n",
            "Epoch 181/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3020 - accuracy: 0.8811\n",
            "Epoch 182/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3020 - accuracy: 0.8815\n",
            "Epoch 183/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3019 - accuracy: 0.8814\n",
            "Epoch 184/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3019 - accuracy: 0.8815\n",
            "Epoch 185/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3019 - accuracy: 0.8815\n",
            "Epoch 186/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3018 - accuracy: 0.8814\n",
            "Epoch 187/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3017 - accuracy: 0.8814\n",
            "Epoch 188/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3016 - accuracy: 0.8816\n",
            "Epoch 189/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3017 - accuracy: 0.8809\n",
            "Epoch 190/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3016 - accuracy: 0.8815\n",
            "Epoch 191/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3016 - accuracy: 0.8813\n",
            "Epoch 192/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3016 - accuracy: 0.8817\n",
            "Epoch 193/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3016 - accuracy: 0.8814\n",
            "Epoch 194/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3014 - accuracy: 0.8811\n",
            "Epoch 195/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3013 - accuracy: 0.8818\n",
            "Epoch 196/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3014 - accuracy: 0.8814\n",
            "Epoch 197/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3014 - accuracy: 0.8815\n",
            "Epoch 198/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.3012 - accuracy: 0.8813\n",
            "Epoch 199/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3012 - accuracy: 0.8818\n",
            "Epoch 200/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3011 - accuracy: 0.8817\n",
            "Epoch 201/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3010 - accuracy: 0.8822\n",
            "Epoch 202/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3008 - accuracy: 0.8825\n",
            "Epoch 203/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.3007 - accuracy: 0.8826\n",
            "Epoch 204/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3006 - accuracy: 0.8827\n",
            "Epoch 205/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.3005 - accuracy: 0.8830\n",
            "Epoch 206/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3004 - accuracy: 0.8832\n",
            "Epoch 207/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.3002 - accuracy: 0.8828\n",
            "Epoch 208/300\n",
            "58831/58831 [==============================] - 2s 36us/step - loss: 0.2999 - accuracy: 0.8831\n",
            "Epoch 209/300\n",
            "58831/58831 [==============================] - 2s 40us/step - loss: 0.2997 - accuracy: 0.8837\n",
            "Epoch 210/300\n",
            "58831/58831 [==============================] - 2s 40us/step - loss: 0.2997 - accuracy: 0.8829\n",
            "Epoch 211/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2994 - accuracy: 0.8831\n",
            "Epoch 212/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2991 - accuracy: 0.8839\n",
            "Epoch 213/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2990 - accuracy: 0.8839\n",
            "Epoch 214/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.2987 - accuracy: 0.8838\n",
            "Epoch 215/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.2987 - accuracy: 0.8838\n",
            "Epoch 216/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2984 - accuracy: 0.8838\n",
            "Epoch 217/300\n",
            "58831/58831 [==============================] - 3s 46us/step - loss: 0.2984 - accuracy: 0.8846\n",
            "Epoch 218/300\n",
            "58831/58831 [==============================] - 2s 39us/step - loss: 0.2983 - accuracy: 0.8843\n",
            "Epoch 219/300\n",
            "58831/58831 [==============================] - 2s 40us/step - loss: 0.2980 - accuracy: 0.8845\n",
            "Epoch 220/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.2979 - accuracy: 0.8845\n",
            "Epoch 221/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2979 - accuracy: 0.8847\n",
            "Epoch 222/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2978 - accuracy: 0.8846\n",
            "Epoch 223/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2976 - accuracy: 0.8850\n",
            "Epoch 224/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2975 - accuracy: 0.8850\n",
            "Epoch 225/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2975 - accuracy: 0.8846\n",
            "Epoch 226/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2973 - accuracy: 0.8842\n",
            "Epoch 227/300\n",
            "58831/58831 [==============================] - 2s 37us/step - loss: 0.2972 - accuracy: 0.8846\n",
            "Epoch 228/300\n",
            "58831/58831 [==============================] - 2s 41us/step - loss: 0.2972 - accuracy: 0.8848\n",
            "Epoch 229/300\n",
            "58831/58831 [==============================] - 2s 39us/step - loss: 0.2970 - accuracy: 0.8847\n",
            "Epoch 230/300\n",
            "58831/58831 [==============================] - 2s 41us/step - loss: 0.2970 - accuracy: 0.8849\n",
            "Epoch 231/300\n",
            "58831/58831 [==============================] - 2s 42us/step - loss: 0.2970 - accuracy: 0.8848\n",
            "Epoch 232/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.2968 - accuracy: 0.8852\n",
            "Epoch 233/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2968 - accuracy: 0.8845\n",
            "Epoch 234/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2967 - accuracy: 0.8852\n",
            "Epoch 235/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2966 - accuracy: 0.8851\n",
            "Epoch 236/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2965 - accuracy: 0.8848\n",
            "Epoch 237/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.2963 - accuracy: 0.8850\n",
            "Epoch 238/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2964 - accuracy: 0.8856\n",
            "Epoch 239/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2963 - accuracy: 0.8856\n",
            "Epoch 240/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2961 - accuracy: 0.8854\n",
            "Epoch 241/300\n",
            "58831/58831 [==============================] - 2s 36us/step - loss: 0.2963 - accuracy: 0.8852\n",
            "Epoch 242/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2962 - accuracy: 0.8854\n",
            "Epoch 243/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2961 - accuracy: 0.8852\n",
            "Epoch 244/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.2961 - accuracy: 0.8851\n",
            "Epoch 245/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.2960 - accuracy: 0.8853\n",
            "Epoch 246/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2960 - accuracy: 0.8852\n",
            "Epoch 247/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.2960 - accuracy: 0.8854\n",
            "Epoch 248/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.2959 - accuracy: 0.8853\n",
            "Epoch 249/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2959 - accuracy: 0.8854\n",
            "Epoch 250/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2957 - accuracy: 0.8853\n",
            "Epoch 251/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2961 - accuracy: 0.8852\n",
            "Epoch 252/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.2959 - accuracy: 0.8849\n",
            "Epoch 253/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2957 - accuracy: 0.8848\n",
            "Epoch 254/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2958 - accuracy: 0.8853\n",
            "Epoch 255/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2958 - accuracy: 0.8852\n",
            "Epoch 256/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2956 - accuracy: 0.8858\n",
            "Epoch 257/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2956 - accuracy: 0.8852\n",
            "Epoch 258/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2956 - accuracy: 0.8857\n",
            "Epoch 259/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2956 - accuracy: 0.8855\n",
            "Epoch 260/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2956 - accuracy: 0.8853\n",
            "Epoch 261/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.2955 - accuracy: 0.8857\n",
            "Epoch 262/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.2956 - accuracy: 0.8857\n",
            "Epoch 263/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2954 - accuracy: 0.8856\n",
            "Epoch 264/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2955 - accuracy: 0.8854\n",
            "Epoch 265/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2954 - accuracy: 0.8857\n",
            "Epoch 266/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2954 - accuracy: 0.8855\n",
            "Epoch 267/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2954 - accuracy: 0.8855\n",
            "Epoch 268/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2955 - accuracy: 0.8852\n",
            "Epoch 269/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2952 - accuracy: 0.8856\n",
            "Epoch 270/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.2953 - accuracy: 0.8853\n",
            "Epoch 271/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.2954 - accuracy: 0.8853\n",
            "Epoch 272/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2953 - accuracy: 0.8857\n",
            "Epoch 273/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2953 - accuracy: 0.8856\n",
            "Epoch 274/300\n",
            "58831/58831 [==============================] - 2s 32us/step - loss: 0.2951 - accuracy: 0.8854\n",
            "Epoch 275/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2952 - accuracy: 0.8854\n",
            "Epoch 276/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2953 - accuracy: 0.8853\n",
            "Epoch 277/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2952 - accuracy: 0.8859\n",
            "Epoch 278/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2953 - accuracy: 0.8853\n",
            "Epoch 279/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2952 - accuracy: 0.8859\n",
            "Epoch 280/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2952 - accuracy: 0.8857\n",
            "Epoch 281/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2952 - accuracy: 0.8852\n",
            "Epoch 282/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2951 - accuracy: 0.8853\n",
            "Epoch 283/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2950 - accuracy: 0.8855\n",
            "Epoch 284/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2952 - accuracy: 0.8853\n",
            "Epoch 285/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2951 - accuracy: 0.8857\n",
            "Epoch 286/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.2951 - accuracy: 0.8851\n",
            "Epoch 287/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2951 - accuracy: 0.8859\n",
            "Epoch 288/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2951 - accuracy: 0.8855\n",
            "Epoch 289/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.2951 - accuracy: 0.8857\n",
            "Epoch 290/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2950 - accuracy: 0.8853\n",
            "Epoch 291/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2951 - accuracy: 0.8858\n",
            "Epoch 292/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2950 - accuracy: 0.8855\n",
            "Epoch 293/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2951 - accuracy: 0.8855\n",
            "Epoch 294/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2950 - accuracy: 0.8859\n",
            "Epoch 295/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2950 - accuracy: 0.8860\n",
            "Epoch 296/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2950 - accuracy: 0.8856\n",
            "Epoch 297/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2950 - accuracy: 0.8857\n",
            "Epoch 298/300\n",
            "58831/58831 [==============================] - 2s 35us/step - loss: 0.2950 - accuracy: 0.8853\n",
            "Epoch 299/300\n",
            "58831/58831 [==============================] - 2s 33us/step - loss: 0.2950 - accuracy: 0.8855\n",
            "Epoch 300/300\n",
            "58831/58831 [==============================] - 2s 34us/step - loss: 0.2948 - accuracy: 0.8856\n",
            "The accuracy score achieved using Neural Network is: 88.95 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1wz7ng0VpR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "bedbefcc-577e-463c-ec48-73cae47349aa"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/aa/e61819d04ef2bbee778bf4b3a748db1f3ad23512377e43ecfdc3211437a0/catboost-0.23.2-cp36-none-manylinux1_x86_64.whl (64.8MB)\n",
            "\u001b[K     || 64.8MB 68kB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.23.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-DfhYBXO3O-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "3a33d6ab-bde6-4140-883c-8462885f18cb"
      },
      "source": [
        "from catboost import CatBoostClassifier\n",
        "clf = CatBoostClassifier(\n",
        "    iterations=25,\n",
        "#     verbose=5,\n",
        ")\n",
        "\n",
        "clf.fit(\n",
        "    X_train, Y_train,\n",
        "    # cat_features=cat_features,\n",
        "    # eval_set=(X_val, y_val),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.5\n",
            "0:\tlearn: 0.5490524\ttotal: 6.03ms\tremaining: 145ms\n",
            "1:\tlearn: 0.5014558\ttotal: 11.9ms\tremaining: 137ms\n",
            "2:\tlearn: 0.4818061\ttotal: 17.7ms\tremaining: 130ms\n",
            "3:\tlearn: 0.4736797\ttotal: 23.9ms\tremaining: 125ms\n",
            "4:\tlearn: 0.4688828\ttotal: 29.6ms\tremaining: 118ms\n",
            "5:\tlearn: 0.4666044\ttotal: 35.4ms\tremaining: 112ms\n",
            "6:\tlearn: 0.4643248\ttotal: 42ms\tremaining: 108ms\n",
            "7:\tlearn: 0.4628180\ttotal: 47.8ms\tremaining: 102ms\n",
            "8:\tlearn: 0.4606450\ttotal: 53.5ms\tremaining: 95ms\n",
            "9:\tlearn: 0.4594232\ttotal: 59.4ms\tremaining: 89.1ms\n",
            "10:\tlearn: 0.4587118\ttotal: 65.2ms\tremaining: 83ms\n",
            "11:\tlearn: 0.4578018\ttotal: 71ms\tremaining: 77ms\n",
            "12:\tlearn: 0.4567525\ttotal: 77ms\tremaining: 71ms\n",
            "13:\tlearn: 0.4565128\ttotal: 82.8ms\tremaining: 65.1ms\n",
            "14:\tlearn: 0.4555672\ttotal: 88.6ms\tremaining: 59.1ms\n",
            "15:\tlearn: 0.4551930\ttotal: 94.4ms\tremaining: 53.1ms\n",
            "16:\tlearn: 0.4544884\ttotal: 100ms\tremaining: 47.1ms\n",
            "17:\tlearn: 0.4543069\ttotal: 106ms\tremaining: 41.2ms\n",
            "18:\tlearn: 0.4539031\ttotal: 111ms\tremaining: 35.2ms\n",
            "19:\tlearn: 0.4538023\ttotal: 116ms\tremaining: 29.1ms\n",
            "20:\tlearn: 0.4535057\ttotal: 122ms\tremaining: 23.2ms\n",
            "21:\tlearn: 0.4533678\ttotal: 127ms\tremaining: 17.4ms\n",
            "22:\tlearn: 0.4520188\ttotal: 133ms\tremaining: 11.6ms\n",
            "23:\tlearn: 0.4516055\ttotal: 139ms\tremaining: 5.8ms\n",
            "24:\tlearn: 0.4505765\ttotal: 145ms\tremaining: 0us\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7fe60a354470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBpEwqUrVyx3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aec96edc-3c1c-4405-da16-d9f1a54cd191"
      },
      "source": [
        "Y_pred_cat = clf.predict(test_scaled)\n",
        "Y_pred_cat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PilEUQEH8_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "19a22fdf-42e9-45b0-d7b0-343a177ee0ec"
      },
      "source": [
        "Y_pred_xgb = xgb_model.predict(test_scaled)\n",
        "Y_pred_xgb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NqzrDVpIIxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "ba06b8f5-817b-4fca-8f9b-32fb95b36bfb"
      },
      "source": [
        "forsub = pd.DataFrame(test.row_id)\n",
        "forsub['open_flag'] = list(Y_pred_cat)\n",
        "forsub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>open_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55965</th>\n",
              "      <td>55965</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55966</th>\n",
              "      <td>55966</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55967</th>\n",
              "      <td>55967</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55968</th>\n",
              "      <td>55968</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55969</th>\n",
              "      <td>55969</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>55970 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       row_id  open_flag\n",
              "0           0          1\n",
              "1           1          0\n",
              "2           2          0\n",
              "3           3          0\n",
              "4           4          0\n",
              "...       ...        ...\n",
              "55965   55965          0\n",
              "55966   55966          0\n",
              "55967   55967          0\n",
              "55968   55968          1\n",
              "55969   55969          1\n",
              "\n",
              "[55970 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNDSuJTxISlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forsub.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVcjuGR2I9n8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "e88ddf35-c2bf-4336-f9ea-78580ee39d82"
      },
      "source": [
        "!kaggle competitions submit -c open-shopee-code-league-marketing-analytics -f submission.csv -m \"Message\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "\r  0% 0.00/426k [00:00<?, ?B/s]\r100% 426k/426k [00:00<00:00, 2.01MB/s]\n",
            "Successfully submitted to [Open] Shopee Code League - Marketing Analytics"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}